---
tags:
  - operatingsystem
---
## Process Address Space 

In a typical process the address space is divided in this way - 
1. **Code Segment**: Contains the program’s compiled code, i.e., the instructions that the CPU executes.
2. **Static Data Segment** : Contains global and static variables that are initialized or uninitialized at compile-time.
3. **Heap** : The dynamically allocated memory, managed by functions like `malloc` or `new`, grows upwards.
4. **Stack** : Used for function calls, local variables, and control flow; it grows downwards.

#### **Forking a Process** 

When a new process is created via `fork()`, the child process gets an exact copy of the parent’s address space (code, static data, heap, stack). Though they initially share the same data, changes made by the child or parent process do not affect each other due to the concept of **[[copy-on-write]]**.

#### **Thread Creation**
- Each thread has its own **program counter (PC)**, **stack**, and **registers** (specific to each thread’s execution).
- Threads **share the rest of the process’s address space**:
    - The **code**, **static data**, and **heap** are all shared among threads, allowing easy and fast communication.

### Kernel-Level Threads

**Kernel-level threads** are essentially processes without separate address spaces:

- The **kernel scheduler** treats each thread as an independent entity and schedules them individually.
- When a timer interrupt occurs (often generated by the system's clock), the kernel's **scheduler** selects which thread or process to run next.
- A thread switch involves saving the current thread’s context (e.g., registers and program counter) and restoring the context of the next thread.


### **Context Switching (cswitch) Function**

A **context switch** (or `cswitch`) is the mechanism used to switch between processes or threads. For processes, it involves:

- Switching the **address space** (virtual memory mappings).
- Switching the **program counter (PC)**, **registers**, and the **stack pointer (sp)**.

For threads, a `cswitch` only needs to:

- Switch the **program counter (PC)**.
- Save and restore **registers**.
- Switch the **stack pointer (sp)** to point to the new thread’s stack.

Since threads share the same address space, no virtual memory changes are required. This makes thread context switches much faster than process switches.

#### Example `cswitch()` function for threads:

```cpp
struct thread {
    void *sp;   // Stack pointer for the thread
    void *pc;   // Program counter (or instruction pointer)
};

void cswitch(struct thread *current_thread, struct thread *next_thread) {
    // Save the current thread's context (stack pointer, program counter)
    asm volatile("mov %0, sp" : "=r"(current_thread->sp));  // Save current stack pointer
    asm volatile("mov %0, pc" : "=r"(current_thread->pc));  // Save current program counter

    // Load the next thread's context (stack pointer, program counter)
    asm volatile("mov sp, %0" : : "r"(next_thread->sp));  // Restore next thread's stack pointer
    asm volatile("mov pc, %0" : : "r"(next_thread->pc));  // Restore next thread's program counter
}

```
This function demonstrates the basic concept of thread context switching by saving and restoring the stack pointer and program counter. In practice, switching would involve more registers (e.g., general-purpose registers).

### **Advantages of Threads Over Processes**

1. **Lightweight**: Threads consume fewer resources than processes since they share address space and other resources like file descriptors and heap memory.
2. **Faster Creation and Destruction**: Creating and terminating threads is faster than doing the same for processes because no new address space needs to be allocated or freed.
3. **Faster Context Switching**: As threads share the same address space, the kernel does not need to switch virtual memory mappings, making the switch quicker.
4. **Efficient Communication**: Threads can communicate through shared data structures in the same process, avoiding inter-process communication (IPC) mechanisms like pipes, message queues, or shared memory used by processes.

### **User-Level Threads**

User-level threads are managed entirely by a user-space library, with no kernel involvement. The developer can implement functions like `scheduler()` and `cswitch()` to control thread switching in the user space. These threads do not require kernel privilege to create or context-switch between.

#### **Advantages of User-Level Threads:**

- **Lightweight**: Since they operate in user space, user-level threads are lighter than kernel threads.
- **Faster Context Switch**: The `cswitch()` function in user-space threads doesn't involve the kernel, making context switches faster.
- **No Kernel Permission Needed**: User-level thread operations don’t require system calls, making them more efficient for CPU-bound tasks.

#### **Disadvantages of User-Level Threads:**

- **Single Core**: The kernel sees user-level threads as a single process, so they cannot be scheduled across multiple cores.
- **Blocking**: If one user-level thread blocks (e.g., waiting for I/O), the entire process is blocked, including all other user-level threads within the process.

### **Threading Models**

- **1:1 Model**: In this model, each user thread maps to a kernel thread. The kernel schedules each thread individually, allowing full concurrency and parallelism across cores.
![[Pasted image 20240921153445.png]]

- **N:1 Model**: All user-level threads are mapped to a single kernel thread, meaning only one thread can execute at a time. If one thread blocks, all threads block.
![[Pasted image 20240921153506.png]]

- **M Model**: This model maps multiple user threads to multiple kernel threads. It strikes a balance by allowing the kernel to schedule multiple threads while keeping some control in the user space.
![[Pasted image 20240921153516.png]]


## Thread Pool

A **thread pool** is a collection of pre-created threads that can be reused to perform tasks, rather than creating and destroying individual threads for each task. Thread pools are commonly used to improve performance in applications that require frequent, short-lived tasks by reusing a limited number of threads.

### How a Thread Pool Works:
1. **Initialization**: A fixed number of threads are created at the beginning and stored in a pool. These threads are idle, waiting for tasks to be assigned.
2. **Task Submission**: When the application needs to perform a task, instead of creating a new thread, it submits the task to the thread pool.
3. **Thread Assignment**: The thread pool assigns one of its idle threads to execute the task. Once the task is completed, the thread becomes idle again and is ready for the next task.
4. **Reusing Threads**: By reusing threads, thread pools reduce the overhead of creating and destroying threads, which can be expensive in terms of CPU and memory resources.

### Components of a Thread Pool:
1. **Worker Threads**: These are the threads in the pool that execute the tasks.
2. **Task Queue**: A queue where tasks waiting to be executed are stored. If all threads are busy, new tasks are placed in this queue until a thread becomes available.
3. **Thread Pool Manager**: Responsible for managing the worker threads, assigning tasks to them, and handling thread life cycles (such as creating more threads if needed or shutting them down).

### Benefits of Thread Pools:
1. **Improved Performance**: By reusing threads, thread pools avoid the overhead of repeatedly creating and destroying threads.
2. **Resource Management**: Thread pools allow you to limit the number of threads in use, preventing resource exhaustion (e.g., memory or CPU) by having too many threads running simultaneously.
3. **Efficient Task Scheduling**: Tasks are scheduled efficiently by using idle threads, ensuring that resources are used optimally.
4. **Avoiding Thread Overhead**: Creating and destroying threads can be time-consuming and inefficient, especially in high-concurrency applications. Thread pools help mitigate this overhead.

### Thread Pool Example in Java:
Java provides a built-in thread pool implementation through the `ExecutorService` interface, particularly with the `ThreadPoolExecutor` class.

Example:
```java
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

public class ThreadPoolExample {
    public static void main(String[] args) {
        // Create a thread pool with 5 threads
        ExecutorService threadPool = Executors.newFixedThreadPool(5);

        // Submit tasks to the thread pool
        for (int i = 0; i < 10; i++) {
            threadPool.execute(new Task(i));
        }

        // Shutdown the thread pool after completing all tasks
        threadPool.shutdown();
    }
}

class Task implements Runnable {
    private int taskId;

    public Task(int id) {
        this.taskId = id;
    }

    @Override
    public void run() {
        System.out.println("Executing Task: " + taskId + " by Thread: " + Thread.currentThread().getName());
    }
}
```
In this example:
- A fixed thread pool of 5 threads is created using `Executors.newFixedThreadPool(5)`.
- 10 tasks are submitted to the thread pool for execution. Since only 5 threads are available, the first 5 tasks are executed immediately, and the remaining 5 tasks wait in the task queue until a thread becomes available.

### Types of Thread Pools:
1. **Fixed Thread Pool**: A fixed number of threads are created, and they remain constant throughout the program's execution. Once all threads are busy, new tasks wait in the queue until a thread becomes available.
   - Example in Java: `Executors.newFixedThreadPool(int n)`
   
2. **Cached Thread Pool**: A thread pool that creates new threads as needed. Threads that finish their tasks are reused for subsequent tasks. If a thread remains idle for a certain time, it is terminated.
   - Example in Java: `Executors.newCachedThreadPool()`
   
3. **Single Thread Executor**: A thread pool that has only one thread. Tasks are executed sequentially in the order they are submitted.
   - Example in Java: `Executors.newSingleThreadExecutor()`
   
4. **Scheduled Thread Pool**: A thread pool that can schedule tasks to be executed after a certain delay or periodically.
   - Example in Java: `Executors.newScheduledThreadPool(int n)`

### Use Cases for Thread Pools:
1. **Web Servers**: Thread pools are widely used in web servers to handle multiple incoming requests concurrently. Instead of creating a new thread for each request, the server assigns requests to threads in the pool.
2. **Database Connection Pools**: Similar to thread pools, database connection pools reuse connections to avoid the overhead of establishing new connections for each query.
3. **Background Tasks**: Applications that need to perform background tasks like sending emails, logging, or running scheduled jobs can benefit from using thread pools.

### Thread Pool Best Practices:
- **Choosing Pool Size**: The size of the thread pool should be determined based on the nature of the tasks. CPU-bound tasks benefit from a smaller pool (e.g., number of CPU cores), while I/O-bound tasks may benefit from a larger pool.
- **Task Management**: Ensure that the tasks submitted to the pool are efficient and do not block threads unnecessarily. If a task blocks for a long time, it may reduce the pool's efficiency.
- **Graceful Shutdown**: Always shut down the thread pool gracefully to ensure that all tasks complete before the application exits.

### Summary:
Thread pools are an essential concurrency control mechanism in multithreaded applications. They allow for efficient resource management, reduced overhead, and improved performance by reusing threads and controlling the number of active threads.